{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master File Outlining Profile Construction Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import interpolate\n",
    "from metrCalculator import calc_theta\n",
    "from metrCalculator import calc_mix_ratio\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calculate Averaged Profile from Surface to Cloud Top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Set user defined variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>filepath</strong> = path to flight data<br>\n",
    "<strong>filepath_ice</strong> = path to 2DS data<br>\n",
    "<strong>filepath_aero</strong> = path to SMPS data<br>\n",
    "<strong>spath</strong> = path to save output files to<br>\n",
    "<strong>sname</strong> = identifier for what profile is being name. will be used in the name of output files<br>\n",
    "\n",
    "<strong>start</strong> = first index of main flight data to be used for profile from surface to cloud top<br>\n",
    "<strong>stop</strong> = last index of main flight data to be used for profile from surface to cloud top<br>\n",
    "\n",
    "<strong>start_2</strong> = first index of main flight data to be used for profile from cloud top to flight path top<br>\n",
    "<strong>stop_2</strong> = last index of main flight data to be used for profile from cloud top to flight path top<br>\n",
    "\n",
    "<strong>interval</strong> = altitude interval to be averaged over<br>\n",
    "<strong>interval_input</strong>   = altitude interval for input profile<br>\n",
    "\n",
    "<strong>heights</strong> = array of altitude levels to be averaged over (user sets max height)<br>\n",
    "<strong>z_start</strong> = height in m to start above cloud profile at<br>\n",
    "<strong>flightPathTop</strong> = height of the top of the flight path<br>\n",
    "<strong>heights_2</strong> = array of altitude levels from cloud top to flight path top<br>\n",
    "\n",
    "<strong>rho_aero</strong> = density of aerosol in kg/m^3<br>\n",
    "<strong>rho_air</strong> = density of air in kg/m^3<br>\n",
    "\n",
    "<strong>aerosol_start</strong> = first index of SMPS data to be included<br>\n",
    "<strong>aerosol_stop</strong> = last index of SMPS data to be included<br>\n",
    "\n",
    "\n",
    "<strong>SEE PART 12 FOR MCF USER DEFINED VARIABLES</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/flight219/core_masin_20151127_r002_flight219_1hz[1].nc'\n",
    "filepath_ice = '/flight219/UMAN_2DS_20151127_r1_Flight219[1].nc'\n",
    "filepath_aero = '/DataFiles/MAC_smps_dn_cm3.xlsx'\n",
    "spath = '/Profiles/F219/'\n",
    "### save name ###\n",
    "sname = 'flight219'\n",
    "###           ###\n",
    "\n",
    "start = 3167 #~start of cloud pass\n",
    "stop = 15187 # end of flight\n",
    "\n",
    "start_2 = 0 # start of flight\n",
    "stop_2 = 3167 # start of cloud pass\n",
    "\n",
    "interval = 10 #[m]\n",
    "interval_input = 50 #[m]\n",
    "\n",
    "# Make an array of the hieght levels\n",
    "heights = np.arange(0,4020,interval) #Surface to domain top\n",
    "z_start = 1070 # ~cloud pass top\n",
    "flightPathTop = 1550 # ~flight path top\n",
    "heights_2 = np.arange(z_start,flightPathTop,interval) #~cloud pass top to ~flight path top\n",
    "\n",
    "cBase = 370 # cloud base height[m] Used in step 6 to set random noise (from table in paper)\n",
    "\n",
    "rho_aero = 2.170 #kg/m3\n",
    "rho_air = 1.225 #kg/m3\n",
    "\n",
    "aerosol_start = 153 #Selects the correct date from the campaign smps data file\n",
    "aerosol_stop = 173 #Selects the correct date from the campaign smps data file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Read in data, select variables, and save in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(filepath)\n",
    "\n",
    "# Make an nan array to be replaced later\n",
    "nans = np.arange(0,len(data['Time'][start:stop]),1)\n",
    "nans = np.full_like(nans,np.nan,dtype=np.double)\n",
    "\n",
    "selectedData = pd.DataFrame(data={'time[s]':data.variables['Time'][start:stop],'T_DI[K]':data.variables['TAT_DI_R'][start:stop],'T_ND[K]':data.variables['TAT_ND_R'][start:stop],'Td[K]':data.variables['TDEW_BUCK'][start:stop],'Alt[m]':data.variables['ALT_OXTS'][start:stop],'RH':data.variables['HUM_ROSE'][start:stop],'Lat':data.variables['LAT_OXTS'][start:stop],'Lon':data.variables['LON_OXTS'][start:stop],'P[hPa]':data.variables['PS_AIR'][start:stop],'u[m/s]':data.variables['U_OXTS'][start:stop],'v[m/s]':data.variables['V_OXTS'][start:stop],'w[m/s]':data.variables['W_OXTS'][start:stop],'NC_All':nans[:],'NC_HI':nans[:],'NC_MI':nans[:],'NC_LI':nans[:],'NC_S':nans[:],'NC_Accum':nans[:],'Mass_Accum':nans[:],'NC_Aitk':nans[:],'Mass_Aitk':nans[:],'NC_Total':nans[:],'Mass_Total':nans[:],'RandomNoise':nans[:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. Insert ice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iceData = Dataset(filepath_ice)\n",
    "\n",
    "iceTime = pd.DataFrame(data={'Time':iceData['Time_mid'][:]-0.5})\n",
    "time_start = min(selectedData['time[s]'][:]*1.0)\n",
    "start_ice = iceTime[iceTime['Time'] == time_start].index.tolist()\n",
    "start_ice = start_ice[0]\n",
    "stop_ice = len(iceTime[:])\n",
    "\n",
    "iceSet = pd.DataFrame(data={'Time':iceData['Time_mid'][start_ice:stop_ice]-0.5,'NC_All':iceData['NC_All'][start_ice:stop_ice],'NC_HI':iceData['NC_HI'][start_ice:stop_ice],'NC_MI':iceData['NC_MI'][start_ice:stop_ice],'NC_LI':iceData['NC_LI'][start_ice:stop_ice],'NC_S':iceData['NC_S'][start_ice:stop_ice]})\n",
    "\n",
    "\n",
    "#Loop through main data and if the time matches the time in ice data then save the location values\n",
    "#Check for fill values (-9999) and change any to 0.0\n",
    "i = 0\n",
    "j = 0\n",
    "for i in range(len(selectedData)): \n",
    "    if selectedData['time[s]'][i]*1.0 == iceSet['Time'][j]:\n",
    "        if iceSet.at[j,'NC_All'] == -9999:\n",
    "            selectedData.at[i,'NC_All'] = 0.0\n",
    "        else:\n",
    "             selectedData.at[i,'NC_All'] = iceSet.at[j,'NC_All']\n",
    "                \n",
    "        if iceSet.at[j,'NC_HI']  == -9999:\n",
    "            selectedData.at[i,'NC_HI'] = 0.0\n",
    "        else:\n",
    "            selectedData.at[i,'NC_HI'] = iceSet.at[j,'NC_HI']\n",
    "            \n",
    "        if iceSet.at[j,'NC_MI']  == -9999:\n",
    "            selectedData.at[i,'NC_MI'] = 0.0\n",
    "        else:\n",
    "            selectedData.at[i,'NC_MI'] = iceSet.at[j,'NC_MI']\n",
    "            \n",
    "        if iceSet.at[j,'NC_LI']  == -9999:\n",
    "            selectedData.at[i,'NC_LI'] = 0.0\n",
    "        else:\n",
    "            selectedData.at[i,'NC_LI'] = iceSet.at[j,'NC_LI']\n",
    "    \n",
    "        if iceSet.at[j,'NC_S']  == -9999:\n",
    "            selectedData.at[i,'NC_S'] = 0.0\n",
    "        else:\n",
    "            selectedData.at[i,'NC_S'] = iceSet.at[j,'NC_S']\n",
    "            \n",
    "        j += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d. Sort data by altitude and reset indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedData = selectedData.sort_values('Alt[m]')\n",
    "selectedData = selectedData.reset_index()\n",
    "\n",
    "selectedData.to_excel(spath + sname + '_selectedData.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1e. Make arrays to be used in average calcuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty (zeros) array of the same length as hieghts\n",
    "zeros = np.zeros(len(heights))\n",
    "\n",
    "# Make an empty dataframe to store the averaged data in\n",
    "avg = pd.DataFrame(data={'z[m]':heights[:],'T_DI[K]':zeros[:],'T_ND[K]':zeros[:],'RH':zeros[:],'theta_DI[K]':zeros[:],'theta_ND[K]':zeros[:],'mix_ratio_DI[kg/kg]':zeros[:],'mix_ratio_ND[kg/kg]':zeros[:],'P[hPa]':zeros[:],'u[m/s]':zeros[:],'v[m/s]':zeros[:],'w[m/s]':zeros[:],'NC_All':zeros[:],'NC_HI':zeros[:],'NC_MI':zeros[:],'NC_LI':zeros[:],'NC_S':zeros[:],'NC_Accum':zeros[:],'Mass_Accum':zeros[:],'NC_Aitk':zeros[:],'Mass_Aitk':zeros[:],'NC_Total':zeros[:],'Mass_Total':zeros[:],'RandomNoise':zeros[:]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1f. Calculate the averaged profile and save to excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through z\n",
    "for z in heights:\n",
    "    sumTDI = 0\n",
    "    countTDI = 0\n",
    "    sumTND = 0\n",
    "    countTND = 0\n",
    "    sumRH = 0\n",
    "    countRH = 0\n",
    "    sumLat = 0\n",
    "    countLat = 0\n",
    "    sumLon = 0\n",
    "    countLon = 0\n",
    "    sumP = 0\n",
    "    countP = 0\n",
    "    sumU = 0\n",
    "    countU = 0\n",
    "    sumV = 0\n",
    "    countV = 0\n",
    "    sumW = 0\n",
    "    countW = 0\n",
    "    sumAI = 0\n",
    "    countAI = 0\n",
    "    sumHI = 0\n",
    "    countHI = 0\n",
    "    sumMI = 0\n",
    "    countMI = 0\n",
    "    sumLI = 0\n",
    "    countLI = 0\n",
    "    sumS = 0\n",
    "    countS = 0\n",
    "\n",
    "    print(z)\n",
    "    #print(len(selectedData))\n",
    "    selectedData = selectedData.reset_index(drop=True)\n",
    "\n",
    "    # loop through data rows\n",
    "    for i in range(len(selectedData)):\n",
    "        # Check if the current altitude is in the current height interval\n",
    "        # If it is then continue to the average calculations, if not do nothing\n",
    "        if selectedData['Alt[m]'][i] > z and selectedData['Alt[m]'][i] < z+interval:\n",
    "            # Check that the current value is not NaN. If NaN do nothing.\n",
    "            # If there is a value then add it to the running sum and add 1 to count.\n",
    "            if math.isnan(selectedData['T_DI[K]'][i]) == False:\n",
    "                sumTDI = sumTDI + selectedData['T_DI[K]'][i]\n",
    "                countTDI += 1\n",
    "            if math.isnan(selectedData['T_ND[K]'][i]) == False:\n",
    "                sumTND = sumTND + selectedData['T_ND[K]'][i]\n",
    "                countTND += 1\n",
    "            if math.isnan(selectedData['RH'][i]) == False:\n",
    "                sumRH = sumRH + selectedData['RH'][i]\n",
    "                countRH += 1\n",
    "            if math.isnan(selectedData['Lat'][i]) == False:\n",
    "                sumLat = sumLat + selectedData['Lat'][i]\n",
    "                countLat += 1\n",
    "            if math.isnan(selectedData['Lon'][i]) == False:\n",
    "                sumLon = sumLon + selectedData['Lon'][i]\n",
    "                countLon += 1\n",
    "            if math.isnan(selectedData['P[hPa]'][i]) == False:\n",
    "                sumP = sumP + selectedData['P[hPa]'][i]\n",
    "                countP += 1\n",
    "            if math.isnan(selectedData['u[m/s]'][i]) == False:\n",
    "                sumU = sumU + selectedData['u[m/s]'][i]\n",
    "                countU += 1\n",
    "            if math.isnan(selectedData['v[m/s]'][i]) == False:\n",
    "                sumV = sumV + selectedData['v[m/s]'][i]\n",
    "                countV += 1\n",
    "            if math.isnan(selectedData['w[m/s]'][i]) == False:\n",
    "                sumW = sumW + selectedData['w[m/s]'][i]\n",
    "                countW += 1\n",
    "            if math.isnan(selectedData['NC_All'][i]) == False:\n",
    "                sumAI = sumAI + selectedData['NC_All'][i]\n",
    "                countAI += 1\n",
    "            if math.isnan(selectedData['NC_HI'][i]) == False:\n",
    "                sumHI = sumHI + selectedData['NC_HI'][i]\n",
    "                countHI += 1\n",
    "            if math.isnan(selectedData['NC_MI'][i]) == False:\n",
    "                sumMI = sumMI + selectedData['NC_MI'][i]\n",
    "                countMI += 1\n",
    "            if math.isnan(selectedData['NC_LI'][i]) == False:\n",
    "                sumLI = sumLI + selectedData['NC_LI'][i]\n",
    "                countAI += 1\n",
    "            if math.isnan(selectedData['NC_S'][i]) == False:\n",
    "                sumS = sumS + selectedData['NC_S'][i]\n",
    "                countS += 1\n",
    "\n",
    "            # Delete the used row\n",
    "            selectedData = selectedData.drop(i,axis=0)\n",
    "\n",
    "        # Check that there were values in the interval. If there were then\n",
    "        # calculate the average. If not set average to NaN.\n",
    "        if countTDI > 0:\n",
    "            avg.at[z/interval,'T_DI[K]'] = sumTDI/countTDI\n",
    "        else:\n",
    "            avg.at[z/interval,'T_DI[K]'] = 'NaN'\n",
    "        if countTND > 0:\n",
    "            avg.at[z/interval,'T_ND[K]'] = sumTND/countTND\n",
    "        else:\n",
    "            avg.at[z/interval,'T_ND[K]'] = 'NaN'\n",
    "        if countRH > 0:\n",
    "            avg.at[z/interval,'RH'] = sumRH/countRH\n",
    "        else:\n",
    "            avg.at[z/interval,'RH'] = 'NaN'\n",
    "        if countLat > 0:\n",
    "            avg.at[z/interval,'Lat'] = sumLat/countLat\n",
    "        else:\n",
    "            avg.at[z/interval,'Lat'] = 'NaN'\n",
    "        if countLon > 0:\n",
    "            avg.at[z/interval,'Lon'] = sumLon/countLon\n",
    "        else:\n",
    "            avg.at[z/interval,'Lon'] = 'NaN'\n",
    "        if countP > 0:\n",
    "            avg.at[z/interval,'P[hPa]'] = sumP/countP\n",
    "        else:\n",
    "            avg.at[z/interval,'P[hPa]'] = 'NaN'\n",
    "        if countU > 0:\n",
    "            avg.at[z/interval,'u[m/s]'] = sumU/countU\n",
    "        else:\n",
    "            avg.at[z/interval,'u[m/s]'] = 'NaN'\n",
    "        if countV > 0:\n",
    "            avg.at[z/interval,'v[m/s]'] = sumV/countV\n",
    "        else:\n",
    "            avg.at[z/interval,'v[m/s]'] = 'NaN'\n",
    "        if countW > 0:\n",
    "            avg.at[z/interval,'w[m/s]'] = sumW/countW\n",
    "        else:\n",
    "            avg.at[z/interval,'w[m/s]'] = 'NaN'\n",
    "        if countAI > 0:\n",
    "            avg.at[z/interval,'NC_All'] = sumAI/countAI\n",
    "        else:\n",
    "            avg.at[z/interval,'NC_All'] = 'NaN'\n",
    "        if countHI > 0:\n",
    "            avg.at[z/interval,'NC_HI'] = sumHI/countHI\n",
    "        else:\n",
    "            avg.at[z/interval,'NC_HI'] = 'NaN'\n",
    "        if countMI > 0:\n",
    "            avg.at[z/interval,'NC_MI'] = sumMI/countMI\n",
    "        else:\n",
    "            avg.at[z/interval,'NC_MI'] = 'NaN'\n",
    "        if countLI > 0:\n",
    "            avg.at[z/interval,'NC_LI'] = sumLI/countLI\n",
    "        else:\n",
    "            avg.at[z/interval,'NC_LI'] = 'NaN'\n",
    "        if countS > 0:\n",
    "            avg.at[z/interval,'NC_S'] = sumS/countS\n",
    "        else:\n",
    "            avg.at[z/interval,'NC_S'] = 'NaN'\n",
    "\n",
    "\n",
    "avg.to_excel(spath + sname + '_avg_1.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate Averaged Profile from Cloud Top to Flight Path Top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Read in data, select variables, and save in DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(filepath)\n",
    "\n",
    "# Make an nan array to be replaced later\n",
    "nans = np.arange(0,len(data['Time'][start_2:stop_2]),1)\n",
    "nans = np.full_like(nans,np.nan,dtype=np.double)\n",
    "\n",
    "selectedData = pd.DataFrame(data={'time[s]':data.variables['Time'][start_2:stop_2],'T_DI[K]':data.variables['TAT_DI_R'][start_2:stop_2],'T_ND[K]':data.variables['TAT_ND_R'][start_2:stop_2],'Td[K]':data.variables['TDEW_BUCK'][start_2:stop_2],'Alt[m]':data.variables['ALT_OXTS'][start_2:stop_2],'RH':data.variables['HUM_ROSE'][start_2:stop_2],'Lat':data.variables['LAT_OXTS'][start_2:stop_2],'Lon':data.variables['LON_OXTS'][start_2:stop_2],'P[hPa]':data.variables['PS_AIR'][start_2:stop_2],'u[m/s]':data.variables['U_OXTS'][start_2:stop_2],'v[m/s]':data.variables['V_OXTS'][start_2:stop_2],'w[m/s]':data.variables['W_OXTS'][start_2:stop_2],'NC_All':nans[:],'NC_HI':nans[:],'NC_MI':nans[:],'NC_LI':nans[:],'NC_S':nans[:],'NC_Accum':nans[:],'Mass_Accum':nans[:],'NC_Aik':nans[:],'Mass_Aik':nans[:],'NC_Total':nans[:],'Mass_Total':nans[:],'RandomNoise':nans[:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Insert ice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iceData = Dataset(filepath_ice)\n",
    "\n",
    "iceTime = pd.DataFrame(data={'Time':iceData['Time_mid'][:]-0.5})\n",
    "time_start = min(selectedData['time[s]'][:]*1.0)\n",
    "\n",
    "if time_start < min(iceTime['Time'][:]):\n",
    "    start_ice = iceTime[iceTime['Time'] == min(iceTime['Time'][:])].index.tolist()\n",
    "else:  \n",
    "    start_ice = iceTime[iceTime['Time'] == time_start].index.tolist()\n",
    "    \n",
    "start_ice = start_ice[0]\n",
    "stop_ice = len(iceTime[:])\n",
    "\n",
    "iceSet = pd.DataFrame(data={'Time':iceData['Time_mid'][start_ice:stop_ice]-0.5,'NC_All':iceData['NC_All'][start_ice:stop_ice],'NC_HI':iceData['NC_HI'][start_ice:stop_ice],'NC_MI':iceData['NC_MI'][start_ice:stop_ice],'NC_LI':iceData['NC_LI'][start_ice:stop_ice],'NC_S':iceData['NC_S'][start_ice:stop_ice]})\n",
    "\n",
    "\n",
    "#Loop through main data and if the time matches the time in ice data then save the location values\n",
    "i = 0\n",
    "j = 0\n",
    "for i in range(len(selectedData)): \n",
    "    if selectedData['time[s]'][i]*1.0 == iceSet['Time'][j]:\n",
    "        if iceSet.at[j,'NC_All'] == -9999:\n",
    "            selectedData.at[i,'NC_All'] = 0.0\n",
    "        else:\n",
    "             selectedData.at[i,'NC_All'] = iceSet.at[j,'NC_All']\n",
    "                \n",
    "        if iceSet.at[j,'NC_HI']  == -9999:\n",
    "            selectedData.at[i,'NC_HI'] = 0.0\n",
    "        else:\n",
    "            selectedData.at[i,'NC_HI'] = iceSet.at[j,'NC_HI']\n",
    "            \n",
    "        if iceSet.at[j,'NC_MI']  == -9999:\n",
    "            selectedData.at[i,'NC_MI'] = 0.0\n",
    "        else:\n",
    "            selectedData.at[i,'NC_MI'] = iceSet.at[j,'NC_MI']\n",
    "            \n",
    "        if iceSet.at[j,'NC_LI']  == -9999:\n",
    "            selectedData.at[i,'NC_LI'] = 0.0\n",
    "        else:\n",
    "            selectedData.at[i,'NC_LI'] = iceSet.at[j,'NC_LI']\n",
    "    \n",
    "        if iceSet.at[j,'NC_S']  == -9999:\n",
    "            selectedData.at[i,'NC_S'] = 0.0\n",
    "        else:\n",
    "            selectedData.at[i,'NC_S'] = iceSet.at[j,'NC_S']\n",
    "            \n",
    "        j += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c. Sort data by altitude and reset indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedData = selectedData.sort_values('Alt[m]')\n",
    "selectedData = selectedData.reset_index()\n",
    "\n",
    "selectedData.to_excel(spath + sname + '_selectedData_2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d. Make arrays to be used in average calcuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty (zeros) array of the same length as hieghts\n",
    "zeros = np.zeros(len(heights_2))\n",
    "\n",
    "# Make an empty dataframe to store the averaged data in\n",
    "avg_2 = pd.DataFrame(data={'z[m]':heights_2[:],'T_DI[K]':zeros[:],'T_ND[K]':zeros[:],'RH':zeros[:],'theta_DI[K]':zeros[:],'theta_ND[K]':zeros[:],'mix_ratio_DI[kg/kg]':zeros[:],'mix_ratio_ND[kg/kg]':zeros[:],'P[hPa]':zeros[:],'u[m/s]':zeros[:],'v[m/s]':zeros[:],'w[m/s]':zeros[:],'NC_All':zeros[:],'NC_HI':zeros[:],'NC_MI':zeros[:],'NC_LI':zeros[:],'NC_S':zeros[:],'NC_Accum':zeros[:],'Mass_Accum':zeros[:],'NC_Aik':zeros[:],'Mass_Aik':zeros[:],'NC_Total':zeros[:],'Mass_Total':zeros[:],'RandomNoise':zeros[:]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2e. Calculate the averaged profile and save to excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through z\n",
    "for z in heights_2:\n",
    "    sumTDI = 0\n",
    "    countTDI = 0\n",
    "    sumTND = 0\n",
    "    countTND = 0\n",
    "    sumRH = 0\n",
    "    countRH = 0\n",
    "    sumLat = 0\n",
    "    countLat = 0\n",
    "    sumLon = 0\n",
    "    countLon = 0\n",
    "    sumP = 0\n",
    "    countP = 0\n",
    "    sumU = 0\n",
    "    countU = 0\n",
    "    sumV = 0\n",
    "    countV = 0\n",
    "    sumW = 0\n",
    "    countW = 0\n",
    "    sumAI = 0\n",
    "    countAI =0\n",
    "    sumHI = 0\n",
    "    countHI = 0\n",
    "    sumMI = 0\n",
    "    countMI = 0\n",
    "    sumLI = 0\n",
    "    countLI = 0\n",
    "    sumS = 0\n",
    "    countS = 0\n",
    "\n",
    "    print(z)\n",
    "    #print(len(selectedData))\n",
    "    selectedData = selectedData.reset_index(drop=True)\n",
    "\n",
    "    # loop through data rows\n",
    "    for i in range(len(selectedData)):\n",
    "        # Check if the current altitude is in the current height interval\n",
    "        # If it is then continue to the average calculations, if not do nothing\n",
    "        if selectedData['Alt[m]'][i] > z and selectedData['Alt[m]'][i] < z+interval:\n",
    "            # Check that the current value is not NaN. If NaN do nothing.\n",
    "            # If there is a value then add it to the running sum and add 1 to count.\n",
    "            if math.isnan(selectedData['T_DI[K]'][i]) == False:\n",
    "                sumTDI = sumTDI + selectedData['T_DI[K]'][i]\n",
    "                countTDI += 1\n",
    "            if math.isnan(selectedData['T_ND[K]'][i]) == False:\n",
    "                sumTND = sumTND + selectedData['T_ND[K]'][i]\n",
    "                countTND += 1\n",
    "            if math.isnan(selectedData['RH'][i]) == False:\n",
    "                sumRH = sumRH + selectedData['RH'][i]\n",
    "                countRH += 1\n",
    "            if math.isnan(selectedData['Lat'][i]) == False:\n",
    "                sumLat = sumLat + selectedData['Lat'][i]\n",
    "                countLat += 1\n",
    "            if math.isnan(selectedData['Lon'][i]) == False:\n",
    "                sumLon = sumLon + selectedData['Lon'][i]\n",
    "                countLon += 1\n",
    "            if math.isnan(selectedData['P[hPa]'][i]) == False:\n",
    "                sumP = sumP + selectedData['P[hPa]'][i]\n",
    "                countP += 1\n",
    "            if math.isnan(selectedData['u[m/s]'][i]) == False:\n",
    "                sumU = sumU + selectedData['u[m/s]'][i]\n",
    "                countU += 1\n",
    "            if math.isnan(selectedData['v[m/s]'][i]) == False:\n",
    "                sumV = sumV + selectedData['v[m/s]'][i]\n",
    "                countV += 1\n",
    "            if math.isnan(selectedData['w[m/s]'][i]) == False:\n",
    "                sumW = sumW + selectedData['w[m/s]'][i]\n",
    "                countW += 1\n",
    "            if math.isnan(selectedData['NC_All'][i]) == False:\n",
    "                sumAI = sumAI + selectedData['NC_All'][i]\n",
    "                countAI += 1\n",
    "            if math.isnan(selectedData['NC_HI'][i]) == False:\n",
    "                sumHI = sumHI + selectedData['NC_HI'][i]\n",
    "                countHI += 1\n",
    "            if math.isnan(selectedData['NC_MI'][i]) == False:\n",
    "                sumMI = sumMI + selectedData['NC_MI'][i]\n",
    "                countMI += 1\n",
    "            if math.isnan(selectedData['NC_LI'][i]) == False:\n",
    "                sumLI = sumLI + selectedData['NC_LI'][i]\n",
    "                countAI += 1\n",
    "            if math.isnan(selectedData['NC_S'][i]) == False:\n",
    "                sumS = sumS + selectedData['NC_S'][i]\n",
    "                countS += 1\n",
    "\n",
    "            # Delete the used row\n",
    "            selectedData = selectedData.drop(i,axis=0)\n",
    "\n",
    "        # Check that there were values in the interval. If there were then\n",
    "        # calculate the average. If not set average to NaN.\n",
    "        tempz = z-z_start\n",
    "        \n",
    "        if countTDI > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'T_DI[K]'] = sumTDI/countTDI\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'T_DI[K]'] = 'NaN'\n",
    "        if countTND > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'T_ND[K]'] = sumTND/countTND\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'T_ND[K]'] = 'NaN'\n",
    "        if countRH > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'RH'] = sumRH/countRH\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'RH'] = 'NaN'\n",
    "        if countLat > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'Lat'] = sumLat/countLat\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'Lat'] = 'NaN'\n",
    "        if countLon > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'Lon'] = sumLon/countLon\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'Lon'] = 'NaN'\n",
    "        if countP > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'P[hPa]'] = sumP/countP\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'P[hPa]'] = 'NaN'\n",
    "        if countU > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'u[m/s]'] = sumU/countU\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'u[m/s]'] = 'NaN'\n",
    "        if countV > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'v[m/s]'] = sumV/countV\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'v[m/s]'] = 'NaN'\n",
    "        if countW > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'w[m/s]'] = sumW/countW\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'w[m/s]'] = 'NaN'\n",
    "        if countAI > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_All'] = sumAI/countAI\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_All'] = 'NaN'\n",
    "        if countHI > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_HI'] = sumHI/countHI\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_HI'] = 'NaN'\n",
    "        if countMI > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_MI'] = sumMI/countMI\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_MI'] = 'NaN'\n",
    "        if countLI > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_LI'] = sumLI/countLI\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_LI'] = 'NaN'\n",
    "        if countS > 0:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_S'] = sumS/countS\n",
    "        else:\n",
    "            avg_2.at[(z-z_start)/interval,'NC_S'] = 'NaN'\n",
    "\n",
    "avg_2.to_excel(spath + sname + '_avg_2.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merge the results from part 2. into the profile from part 1. and save into excel spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in heights_2[1:len(heights)]/10:\n",
    "    i = int(i)\n",
    "    avg.at[i,'T_DI[K]']=avg_2['T_DI[K]'][j]\n",
    "    avg.at[i,'T_ND[K]']=avg_2['T_ND[K]'][j]\n",
    "    avg.at[i,'RH']=avg_2['RH'][j]\n",
    "    avg.at[i,'Lat']=avg_2['Lat'][j]\n",
    "    avg.at[i,'Lon']=avg_2['Lon'][j]\n",
    "    avg.at[i,'P[hPa]']=avg_2['P[hPa]'][j]\n",
    "    avg.at[i,'u[m/s]']=avg_2['u[m/s]'][j]\n",
    "    avg.at[i,'v[m/s]']=avg_2['v[m/s]'][j]\n",
    "    avg.at[i,'w[m/s]']=avg_2['w[m/s]'][j]\n",
    "    avg.at[i,'NC_All']=avg_2['NC_All'][j]\n",
    "    avg.at[i,'NC_HI'] =avg_2['NC_HI'][j]\n",
    "    avg.at[i,'NC_MI'] =avg_2['NC_MI'][j]\n",
    "    avg.at[i,'NC_LI'] =avg_2['NC_LI'][j]\n",
    "    avg.at[i,'NC_S'] =avg_2['NC_S'][j]\n",
    "    j+=1\n",
    "    \n",
    "avg.to_excel(spath + sname + '_avg_3.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extrapolate the data at the top of the flight data to make the profile go up to 4000 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_4 = avg[:]\n",
    "variables = ['T_DI[K]','T_ND[K]','P[hPa]']\n",
    "variables_2 = ['RH','Lat','Lon','u[m/s]','v[m/s]','w[m/s]']\n",
    "\n",
    "for var in variables:\n",
    "    x = avg_2[var][len(avg_2)-8:len(avg_2)-2]\n",
    "    y = avg_2['z[m]'][len(avg_2)-8:len(avg_2)-2]\n",
    "\n",
    "    f = interpolate.interp1d(y,x,fill_value=\"extrapolate\",kind=\"linear\")\n",
    "    ynew = np.arange(flightPathTop,4030,10)\n",
    "    xnew = f(ynew)\n",
    "\n",
    "    j = 0\n",
    "    for i in range(int(flightPathTop/10),403,1):\n",
    "        avg_4.loc[i,var] = xnew[j]\n",
    "        j += 1\n",
    "\n",
    "\n",
    "for var in variables_2:\n",
    "    x = avg_2[var][len(avg_2)-8:len(avg_2)-2]\n",
    "    y = avg_2['z[m]'][len(avg_2)-8:len(avg_2)-2]\n",
    "\n",
    "    f = interpolate.interp1d(y,x,fill_value=\"extrapolate\",kind=\"previous\")\n",
    "    ynew = np.arange(flightPathTop,4030,10)\n",
    "    xnew = f(ynew)\n",
    "\n",
    "    j = 0\n",
    "    for i in range(int(flightPathTop/10),403,1):\n",
    "        avg_4.loc[i,var] = xnew[j]\n",
    "        j += 1\n",
    "\n",
    "\n",
    "avg_4.to_excel(spath + sname + '_avg_4.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Calculate potential temperature and vapour mixing ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(avg)):\n",
    "    # if any of the values are NaN then skip the row, otherwise run the calculation\n",
    "    if avg_4.at[i,'theta_DI[K]'] == 'NaN' or avg_4.at[i,'P[hPa]'] == 'NaN':\n",
    "        print('NaN at row: ' + str(i))\n",
    "        avg_4.at[i,'theta_DI[K]'] = 'NaN'\n",
    "    else:\n",
    "        avg_4.at[i,'theta_DI[K]'] = calc_theta(avg_4.at[i,'T_DI[K]'],avg_4.at[i,'P[hPa]'],1000)\n",
    "    \n",
    "    if avg_4.at[i,'theta_ND[K]'] == 'NaN' or avg_4.at[i,'P[hPa]'] == 'NaN':\n",
    "        print('NaN at row: ' + str(i))\n",
    "        avg_4.at[i,'theta_ND[K]'] = 'NaN'\n",
    "    else:\n",
    "        avg_4.at[i,'theta_ND[K]'] = calc_theta(avg_4.at[i,'T_ND[K]'],avg_4.at[i,'P[hPa]'],1000)\n",
    "    \n",
    "    if avg_4.at[i,'mix_ratio_DI[kg/kg]'] == 'NaN' or avg_4.at[i,'P[hPa]'] == 'NaN':\n",
    "        print('NaN at row: ' + str(i))\n",
    "        avg_4.at[i,'mix_ratio_DI[kg/kg]'] = 'NaN'\n",
    "    else:\n",
    "        avg_4.at[i,'mix_ratio_DI[kg/kg]'] = calc_mix_ratio(avg_4.at[i,'P[hPa]'],avg_4.at[i,'T_DI[K]'],avg.at[i,'RH'])\n",
    "    \n",
    "    if avg_4.at[i,'mix_ratio_ND[kg/kg]'] == 'NaN' or avg_4.at[i,'P[hPa]'] == 'NaN':\n",
    "        print('NaN at row: ' + str(i))\n",
    "        avg_4.at[i,'mix_ratio_ND[kg/kg]'] = 'NaN'\n",
    "    else:\n",
    "        avg_4.at[i,'mix_ratio_ND[kg/kg]'] = calc_mix_ratio(avg_4.at[i,'P[hPa]'],avg_4.at[i,'T_ND[K]'],avg.at[i,'RH'])\n",
    "    \n",
    "    \n",
    "avg_4.to_excel(spath + sname + '_avg_5.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Set random noise to 0.1 below cloud base and 0.0001 above cloud base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cBaseIndex = np.where(avg_4['z[m]'][:] == cBase)\n",
    "\n",
    "for i in range(0,cBaseIndex[0][0],1):\n",
    "    avg_4.at[i,'RandomNoise'] = 0.1\n",
    "\n",
    "for i in range(cBaseIndex[0][0],len(heights)):\n",
    "    avg_4.at[i,'RandomNoise'] = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Calculate aerosol data and input into dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7a. Calcuate aerosol number concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads in data and gets the dataframe into a nice format\n",
    "data = pd.read_excel(filepath_aero)\n",
    "data = data[aerosol_start:aerosol_stop]\n",
    "binSizes = data.columns.values.tolist() #saves bin sizes for reference later\n",
    "data = data.reset_index()\n",
    "data = data.drop(columns='index')\n",
    "data = data.T\n",
    "data = data.rename({'Unnamed: 0':'Date','Unnamed: 1':'time',20.4250952021526:0, 22.4325910999881:1, 24.6437117917855:2, 27.0809844387799:3, 29.7694227451051:4, 32.7357551943633:5, 36.0153628336391:6, 39.6414443158088:7, 43.657769753255:8, 48.1074387452588:9, 53.0463834603934:10, 58.5367022693272:11, 64.6494708948485:12, 71.4701788306466:13, 79.0960792172577:14, 87.6397387949133:15, 97.2414070232693:16, 108.05511526259:17, 120.278143540756:18, 134.136463370406:19, 149.913582565337:20, 167.943965022015:21, 188.639754038945:22, 212.483927696124:23, 240.09271275061:24, 272.20857095331:25, 309.605498652495:26}, axis='index')\n",
    "\n",
    "# Aitken mode\n",
    "sum_Aitk = np.zeros((aerosol_stop-aerosol_start))\n",
    "\n",
    "#Calculate running sum of Aitken particles. (Ignore negative values)\n",
    "for c in range(0,(aerosol_stop-aerosol_start),1):\n",
    "    for i in range(0,17,1):\n",
    "        if data[c][i] >= 0:\n",
    "            sum_Aitk[c] = sum_Aitk[c] + data[c][i]\n",
    "\n",
    "Aitk_Total_avg = 0 #Total number of Aitken particles per cm^3\n",
    "for i in range(len(sum_Aitk)):\n",
    "    Aitk_Total_avg = Aitk_Total_avg + sum_Aitk[i]\n",
    "\n",
    "Aitk_Total_avg = Aitk_Total_avg / (aerosol_stop - aerosol_start)\n",
    "Aitk_Total_avg = Aitk_Total_avg * 1000000.0 #Total number of Aitken particles per m^3\n",
    "Aitk_Total_avg = Aitk_Total_avg / rho_air #Convert to per kg\n",
    "\n",
    "\n",
    "# Accumulation mode\n",
    "sum_Accu = np.zeros((aerosol_stop-aerosol_start))\n",
    "\n",
    "#Calculate running sum of Aitken particles. (Ignore negative values)\n",
    "for c in range(0,(aerosol_stop-aerosol_start),1):\n",
    "    for i in range(17,26,1):\n",
    "        if data[c][i] >= 0:\n",
    "            sum_Accu[c] = sum_Accu[c] + data[c][i]\n",
    "\n",
    "Accu_Total_avg = 0 #Total number of Accumulation particles per cm^3\n",
    "for i in range(len(sum_Accu)):\n",
    "    Accu_Total_avg = Accu_Total_avg + sum_Accu[i]\n",
    "\n",
    "Accu_Total_avg = Accu_Total_avg / (aerosol_stop - aerosol_start)\n",
    "Accu_Total_avg = Accu_Total_avg * 1000000.0 #Total number of Accumulation particles per m^3\n",
    "Accu_Total_avg = Accu_Total_avg / rho_air #Convert to per kg\n",
    "\n",
    "aero_Total_avg = Aitk_Total_avg + Accu_Total_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7b. Input results into dataframe (note: assumes constant distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(avg_4)):\n",
    "    avg_4.loc[i,'NC_Aitk'] = Aitk_Total_avg\n",
    "    avg_4.loc[i,'NC_Accu'] = Accu_Total_avg\n",
    "    avg_4.loc[i,'NC_Total'] = aero_Total_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7c. Calculate the total mass in each size bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the total number of particles in each size bin (for all modes)\n",
    "sizeBins = np.zeros(len(binSizes)-2)\n",
    "for i in range(len(sizeBins)):\n",
    "    runningSum = 0\n",
    "    count = 0\n",
    "    for j in range(len(data.columns)):\n",
    "        if data[j][i] >= 0:\n",
    "            runningSum = runningSum + data[j][i]\n",
    "            count += 1\n",
    "    \n",
    "    if count > 0:\n",
    "        sizeBins[i] = runningSum / count\n",
    "    \n",
    "#Conver bin diameters from nm to m\n",
    "D = np.zeros(len(binSizes)-2)\n",
    "for i in range(len(D)):\n",
    "    D[i] = float(binSizes[i+2]) * (10**(-9))\n",
    "\n",
    "#Calculate mass in each size bin (for all modes)\n",
    "for i in range(len(sizeBins)):\n",
    "    sizeBins[i] = (D[i] ** 3) * (math.pi/6) * rho_aero * sizeBins[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7d. Calculate the mass mixing ratio for Akitken and Accumulation modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the total mass (Aitken mode)\n",
    "totalMass = 0\n",
    "for i in range(17):\n",
    "    totalMass = totalMass + sizeBins[i]\n",
    "\n",
    "#Convert to kg/kg\n",
    "massMixingRatio_Aitken = (totalMass * (10**6)) / rho_air\n",
    "\n",
    "#Calculate the total mass (Accum mode)\n",
    "totalMass = 0\n",
    "for i in range(17,len(sizeBins),1):\n",
    "    totalMass = totalMass + sizeBins[i]\n",
    "\n",
    "#Convert to kg/kg\n",
    "massMixingRatio_Accum = (totalMass * (10**6)) / rho_air\n",
    "\n",
    "massMixingRatio_Total = massMixingRatio_Aitken + massMixingRatio_Accum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7e. Input results into dataframe (note: assumes constant distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(avg_4)):\n",
    "    avg_4.loc[i,'Mass_Aitk'] = massMixingRatio_Aitken\n",
    "    avg_4.loc[i,'Mass_Accu'] = massMixingRatio_Accum\n",
    "    avg_4.loc[i,'Mass_Total'] = massMixingRatio_Total\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7e. Save to spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_4.to_excel(spath + sname + '_avg.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Plot profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = pd.read_excel(spath + sname + '_avg.xlsx')\n",
    "\n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "plt.subplot(521)\n",
    "# Plot Temperature profile\n",
    "plt.plot(avg['T_DI[K]'][:]-273.15,avg['z[m]'][:],label='T_DI',color='k')\n",
    "plt.plot(avg['T_ND[K]'][:]-273.15,avg['z[m]'][:],label='T_ND',color='r')\n",
    "plt.title('Average Temperature Profiles')\n",
    "plt.xlabel('Temperature [C]')\n",
    "plt.ylabel('Altitude [m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(522)\n",
    "# Plot RH profile\n",
    "plt.plot(avg['RH'][:],avg['z[m]'][:],label='RH',color='g')\n",
    "plt.title('Average Relative Humidity Profile')\n",
    "plt.xlabel('RH [%]')\n",
    "plt.ylabel('Altitude [m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(523)\n",
    "# Plot Potential Temperature profile\n",
    "plt.plot(avg['theta_DI[K]'][:],avg['z[m]'][:],label='theta_DI',color='k')\n",
    "plt.plot(avg['theta_ND[K]'][:],avg['z[m]'][:],label='theta_ND',color='r')\n",
    "plt.title('Potential Temperature [K]')\n",
    "plt.xlabel('Potential Temperature [K]')\n",
    "plt.ylabel('Altitude [m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(524)\n",
    "# Plot Vapour Mixing Ratio profile\n",
    "plt.plot(avg['mix_ratio_DI[kg/kg]'][:],avg['z[m]'][:],label='mixing ratio DI',color='k')\n",
    "plt.plot(avg['mix_ratio_ND[kg/kg]'][:],avg['z[m]'][:],label='mixing ratio ND',color='r')\n",
    "plt.title('Vapour mixing ratio [kg/kg]')\n",
    "plt.xlabel('Vapour Mixing Ratio [kg/kg]')\n",
    "plt.ylabel('Altitude [m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(525)\n",
    "# Plot Pressure profile\n",
    "plt.plot(avg['P[hPa]'][:],avg['z[m]'][:],label='pressure',color='b')\n",
    "plt.title('Average Pressure Profile')\n",
    "plt.xlabel('Pressure [hPa]')\n",
    "plt.ylabel('Altitude [m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(526)\n",
    "# Plot u wind\n",
    "plt.plot(avg['u[m/s]'][:],avg['z[m]'][:],label='u wind',color='k')\n",
    "plt.title('Average U-wind Component')\n",
    "plt.xlabel('U-wind [m/s]')\n",
    "plt.ylabel('Altitude [m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(527)\n",
    "# Plot Lat\n",
    "plt.plot(avg['Lat'][:],avg['z[m]'][:],label='Latitude',color='grey')\n",
    "plt.title('Average Latitude')\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('z[m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(528)\n",
    "# Plot v wind\n",
    "plt.plot(avg['v[m/s]'][:],avg['z[m]'][:],label='v wind',color='k')\n",
    "plt.title('Average V-wind Component')\n",
    "plt.xlabel('V-wind [m/s]')\n",
    "plt.ylabel('Altitude [m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(529)\n",
    "# Plot Lon\n",
    "plt.plot(avg['Lon'][:],avg['z[m]'][:],label='Longitude',color='grey')\n",
    "plt.title('Average Longitude')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Altitude [m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(5,2,10)\n",
    "# Plot w wind\n",
    "plt.plot(avg['w[m/s]'][:],avg['z[m]'][:],label='w wind',color='k')\n",
    "plt.title('Average W-wind Component')\n",
    "plt.xlabel('W-wind [m/s]')\n",
    "plt.ylabel('Altitude [m]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.savefig(spath + sname + '_plots.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Select the data from the specified input interval and save to new excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the extra column that was added during reindexing\n",
    "avg = avg.drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "# Select data for every interval_input m and save to a separate file\n",
    "# Initialize empty array for use later\n",
    "remove = []\n",
    "\n",
    "# Loop through all the rows in avg\n",
    "for i in range(len(avg)):\n",
    "    # If the height[i] is not divisible by interval_input then add row i to list to be removed\n",
    "    if avg['z[m]'][i]%interval_input > 0:\n",
    "        remove.append(i)\n",
    "\n",
    "# Remove the unwanted rows and then save the shortened dataset to an xlsx file\n",
    "#avg.drop(remove).to_excel(spath + sname +'_input_values.xlsx')\n",
    "avg = avg.drop(remove)\n",
    "avg.to_excel(spath + sname + '_input_values.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Plot initial profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(spath + sname + '_plots.pdf') as pp:\n",
    "\n",
    "    # Plot temperature profile\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.plot(avg['T_DI[K]'][:]-273.15,avg['z[m]'][:],label='T_DI',color='r')\n",
    "    plt.plot(avg['T_ND[K]'][:]-273.15,avg['z[m]'][:],label='T_ND',color='b',linestyle='--')\n",
    "    plt.title('Average Temperature Profiles',fontsize=20)\n",
    "    plt.xlabel('Temperature [C]',fontsize=14)\n",
    "    plt.ylabel('Altitude [m]',fontsize=14)\n",
    "    plt.legend()\n",
    "    pp.savefig()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # zoomed in\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.plot(avg['T_DI[K]'][:]-273.15,avg['z[m]'][:],label='T_DI',color='r')\n",
    "    plt.plot(avg['T_ND[K]'][:]-273.15,avg['z[m]'][:],label='T_ND',color='b',linestyle='--')\n",
    "    plt.title('Average Temperature Profiles',fontsize=20)\n",
    "    plt.xlabel('Temperature [C]',fontsize=14)\n",
    "    plt.ylabel('Altitude [m]',fontsize=14)\n",
    "    plt.ylim([0,2000])\n",
    "    plt.xlim([-20,0])\n",
    "    plt.legend()\n",
    "    pp.savefig()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Plot Potential Temperature profile\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.plot(avg['theta_DI[K]'][:],avg['z[m]'][:],label='theta_DI',color='r')\n",
    "    plt.plot(avg['theta_ND[K]'][:],avg['z[m]'][:],label='theta_ND',color='b',linestyle='--')\n",
    "    plt.title('Potential Temperature [K]',fontsize=20)\n",
    "    plt.xlabel('Potential Temperature [K]',fontsize=14)\n",
    "    plt.ylabel('Altitude [m]',fontsize=14)\n",
    "    plt.legend()\n",
    "    pp.savefig()\n",
    "    plt.show()\n",
    "\n",
    "    # zoomed in\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.plot(avg['theta_DI[K]'][:],avg['z[m]'][:],label='theta_DI',color='r')\n",
    "    plt.plot(avg['theta_ND[K]'][:],avg['z[m]'][:],label='theta_ND',color='b',linestyle='--')\n",
    "    plt.title('Potential Temperature [K]',fontsize=20)\n",
    "    plt.xlabel('Potential Temperature [K]',fontsize=14)\n",
    "    plt.ylabel('Altitude [m]',fontsize=14)\n",
    "    plt.ylim([0,2000])\n",
    "    plt.xlim([260,285])\n",
    "    plt.legend()\n",
    "    pp.savefig()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Vapour Mixing Ratio profile\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.plot(avg['mix_ratio_DI[kg/kg]'][:],avg['z[m]'][:],label='mixing ratio DI',color='r')\n",
    "    plt.plot(avg['mix_ratio_ND[kg/kg]'][:],avg['z[m]'][:],label='mixing ratio ND',color='b',linestyle='--')\n",
    "    plt.title('Vapour mixing ratio [kg/kg]',fontsize=20)\n",
    "    plt.xlabel('Vapour Mixing Ratio [kg/kg]',fontsize=14)\n",
    "    plt.ylabel('Altitude [m]',fontsize=14)\n",
    "    plt.legend()\n",
    "    pp.savefig()\n",
    "    plt.show()\n",
    "\n",
    "    # zoomed in\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.plot(avg['mix_ratio_DI[kg/kg]'][:],avg['z[m]'][:],label='mixing ratio DI',color='r')\n",
    "    plt.plot(avg['mix_ratio_ND[kg/kg]'][:],avg['z[m]'][:],label='mixing ratio ND',color='b',linestyle='--')\n",
    "    plt.title('Vapour mixing ratio [kg/kg]',fontsize=20)\n",
    "    plt.xlabel('Vapour Mixing Ratio [kg/kg]',fontsize=14)\n",
    "    plt.ylabel('Altitude [m]',fontsize=14)\n",
    "    plt.ylim([0,2000])\n",
    "    plt.legend()\n",
    "    pp.savefig()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Convert profile data to format need by model and save to txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = pd.read_excel(spath + sname + '_input_values.xlsx')\n",
    "\n",
    "# file = open(spath + sname + '_input_data.txt','w')\n",
    "\n",
    "\n",
    "# file.write('Initial Profile Data for MAC ' + sname +' \\n\\n\\n')\n",
    "\n",
    "# file.write('Altitude [m]:\\n')\n",
    "# file.write(str(input_data['z[m]'][:].round(0).tolist()))\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('Potential Temperature [K]:\\n')\n",
    "# file.write(str(input_data['theta_DI[K]'][:].round(2).tolist()))\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('Vapour Mixing Ratio [kg/kg]:\\n')\n",
    "# file.write(str(input_data['mix_ratio_DI[kg/kg]'][:].round(4).tolist()))\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('Aitken Aerosol Number Concentration [#/kg]:\\n')\n",
    "# x = np.format_float_scientific(input_data['NC_Aitk'][0], precision=2, exp_digits=2)\n",
    "# for i in range(1,len(input_data),1):\n",
    "#     x = x + ', ' + np.format_float_scientific(input_data['NC_Aitk'][i], precision=2, exp_digits=2)\n",
    "# file.write(x)\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('Aitkne Aerosol Mass Mixing Ratio [kg/kg]:\\n')\n",
    "# x = np.format_float_scientific(input_data['Mass_Aitk'][0], precision=2, exp_digits=2)\n",
    "# for i in range(1,len(input_data),1):\n",
    "#     x = x + ', ' + np.format_float_scientific(input_data['Mass_Aitk'][i], precision=2, exp_digits=2)\n",
    "# file.write(x)\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('Accumulation Aerosol Number Concentration [#/kg]:\\n')\n",
    "# x = np.format_float_scientific(input_data['NC_Accu'][0], precision=2, exp_digits=2)\n",
    "# for i in range(1,len(input_data),1):\n",
    "#     x = x + ', ' + np.format_float_scientific(input_data['NC_Accu'][i], precision=2, exp_digits=2)\n",
    "# file.write(x)\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('Accumulation Aerosol Mass Mixing Ratio [kg/kg]:\\n')\n",
    "# x = np.format_float_scientific(input_data['Mass_Accu'][0], precision=2, exp_digits=2)\n",
    "# for i in range(1,len(input_data),1):\n",
    "#     x = x + ', ' + np.format_float_scientific(input_data['Mass_Accu'][i], precision=2, exp_digits=2)\n",
    "# file.write(x)\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('Total Aerosol Number Concentration [#/kg]:\\n')\n",
    "# x = np.format_float_scientific(input_data['NC_Total'][0], precision=2, exp_digits=2)\n",
    "# for i in range(1,len(input_data),1):\n",
    "#     x = x + ', ' + np.format_float_scientific(input_data['NC_Total'][i], precision=2, exp_digits=2)\n",
    "# file.write(x)\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('Total Aerosol Mass Mixing Ratio [kg/kg]:\\n')\n",
    "# x = np.format_float_scientific(input_data['Mass_Total'][0], precision=2, exp_digits=2)\n",
    "# for i in range(1,len(input_data),1):\n",
    "#     x = x + ', ' + np.format_float_scientific(input_data['Mass_Total'][i], precision=2, exp_digits=2)\n",
    "# file.write(x)\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('U Wind [m/s]:\\n')\n",
    "# file.write(str(input_data['u[m/s]'][:].round(2).tolist()))\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.write('V Wind [m/s]:\\n')\n",
    "# file.write(str(input_data['v[m/s]'][:].round(2).tolist()))\n",
    "# file.write('\\n\\n')\n",
    "\n",
    "# file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Create mcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set aerosol type identifier for save name\n",
    "#aeroType = '_accum'\n",
    "#aeroType = '_aitken'\n",
    "aeroType = '_accumAndAitken'\n",
    "\n",
    "#Set variables for MONC configuration file\n",
    "display_synopsis_frequency = 100\n",
    "termination_time = 43260.\n",
    "dtm = 0.2\n",
    "xmlPath = \"INSERT_FILEPATH\"\n",
    "modelSname = \"INSERT_SNAME\"\n",
    "monsPerIO = 11\n",
    "sampling_frequency = 20\n",
    "sampling_frequency_3d = 200\n",
    "mm = 600.0\n",
    "mm1 = 60.0\n",
    "diag_write_freq = 43200.0\n",
    "walltime_limit = \"04:00:00\"\n",
    "\n",
    "### surface data ###\n",
    "thref = 273.31 #From calculations in <checkDataForProfileConstruction>\n",
    "surface_pressure = 97457 #From calculations in <checkDataForProfileConstruction>\n",
    "###              ###\n",
    "\n",
    "x_size = 32\n",
    "y_size = 32\n",
    "z_size =37\n",
    "dxx = 100\n",
    "dyy = 100\n",
    "zztop = 3950\n",
    "kgd = \"2,37\"\n",
    "hgd = \"50,3950\"\n",
    "rmlmax = 23\n",
    "\n",
    "### max cloud height ###\n",
    "maxCloudHeight = 900 #Based on table in paper\n",
    "###                  ###\n",
    "\n",
    "z0 = \"4.5e-4\"\n",
    "z0th = \"2.2e-4\"\n",
    "fcoriol = 0.00014\n",
    "dmptim = 0.001\n",
    "zdmp = 3400.0\n",
    "hdmp = 100.0\n",
    "zSubs = \"0.0,3950\"\n",
    "fSubs = \"0.000005,0.000005\"\n",
    "lat = -75\n",
    "lon = -32\n",
    "\n",
    "### radiation time/date ###\n",
    "rad_start_year = 2015\n",
    "rad_start_day = 331\n",
    "rad_start_time = 19\n",
    "###                     ###\n",
    "surface_albedo = 0.3\n",
    "\n",
    "### Casim options ###\n",
    "act = 4\n",
    "inuc = 2\n",
    "process_level = 0\n",
    "aeroOption = 2\n",
    "q_fields = 17\n",
    "###               ###\n",
    "\n",
    "#Format the profile data\n",
    "z = str(input_data['z[m]'][1].round(0))\n",
    "th = str(input_data['theta_DI[K]'][1].round(2))\n",
    "u = str(input_data['u[m/s]'][1].round(2))\n",
    "v = str(input_data['v[m/s]'][1].round(2))\n",
    "q = str(input_data['mix_ratio_DI[kg/kg]'][1].round(4))\n",
    "num_Aitk = np.format_float_scientific(input_data['NC_Aitk'][1], precision=2, exp_digits=2)\n",
    "mass_Aitk = np.format_float_scientific(input_data['Mass_Aitk'][1], precision=2, exp_digits=2)\n",
    "num_Accu = np.format_float_scientific(input_data['NC_Accu'][1], precision=2, exp_digits=2)\n",
    "mass_Accu = np.format_float_scientific(input_data['Mass_Accu'][1], precision=2, exp_digits=2)\n",
    "num_Total = np.format_float_scientific(input_data['NC_Total'][1], precision=2, exp_digits=2)\n",
    "mass_Total = np.format_float_scientific(input_data['Mass_Total'][1], precision=2, exp_digits=2)\n",
    "\n",
    "rand = str(input_data['RandomNoise'][1].round(4))\n",
    "\n",
    "for i in range(2,len(input_data),1):\n",
    "    z = z + ', ' + str(input_data['z[m]'][i].round(0))\n",
    "    th = th + ', ' + str(input_data['theta_DI[K]'][i].round(2))\n",
    "    u = u + ', ' + str(input_data['u[m/s]'][i].round(2))\n",
    "    v = v + ', ' + str(input_data['v[m/s]'][i].round(2))\n",
    "    q = q + ', ' + str(input_data['mix_ratio_DI[kg/kg]'][i].round(4))\n",
    "    num_Aitk = num_Aitk + ', ' + np.format_float_scientific(input_data['NC_Aitk'][i], precision=2, exp_digits=2)\n",
    "    mass_Aitk = mass_Aitk + ', ' + np.format_float_scientific(input_data['Mass_Aitk'][i], precision=2, exp_digits=2)\n",
    "    num_Accu = num_Accu + ', ' + np.format_float_scientific(input_data['NC_Accu'][i], precision=2, exp_digits=2)\n",
    "    mass_Accu = mass_Accu + ', ' + np.format_float_scientific(input_data['Mass_Accu'][i], precision=2, exp_digits=2)\n",
    "    rand = rand + ', ' + str(input_data['RandomNoise'][i].round(4))\n",
    "    \n",
    "    \n",
    "#Set which aerosol mode(s) to use\n",
    "#names = \"vapour, accum_sol_mass, accum_sol_number\"\n",
    "#mass = mass_Accu\n",
    "#number = num_Accu\n",
    "#names = \"vapour, aitken_sol_mass, aitken_sol_number\"\n",
    "#mass = mass_Aitk\n",
    "#number = num_Aitk\n",
    "names = \"vapour, accum_sol_mass, accum_sol_number, aitken_sol_mass, aitken_sol_number\"\n",
    "\n",
    "\n",
    "#Create MONC configuration file\n",
    "with open(spath + sname + aeroType + '.mcf', \"w\") as file:\n",
    "\n",
    "    file.write('# Global configuration\\n')\n",
    "    file.write('global_configuration=global_config\\n\\n')\n",
    "\n",
    "    file.write('# Override global component defaults\\n')\n",
    "    file.write('simplesetup_enabled=.true.\\n')\n",
    "    file.write('smagorinsky_enabled=.true.\\n')\n",
    "    file.write('lower_bc_enabled=.true.\\n')\n",
    "    file.write('coriolis_enabled=.true.\\n')\n",
    "    file.write('damping_enabled=.true.\\n\\n')\n",
    "\n",
    "    file.write('forcing_enabled=.false.\\n\\n')\n",
    "\n",
    "    file.write('galilean_transformation=.false. # Needs debugging\\n')\n",
    "    file.write('randomnoise_enabled=.true.\\n')\n",
    "    file.write('mean_profiles_enabled=.true. #This must be set to true if running with damping\\n')\n",
    "    file.write('th_advection_enabled=.true.\\n')\n",
    "\n",
    "    file.write('iobridge_enabled=.true.\\n')\n",
    "    file.write('scalar_diagnostics_enabled=.true.\\n')\n",
    "    file.write('profile_diagnostics_enabled=.true.\\n')\n",
    "    file.write('diagnostics_3d_enabled=.true.\\n\\n')\n",
    "\n",
    "    file.write('simplecloud_enabled=.false.\\n')\n",
    "    file.write('casim_enabled=.true.\\n')\n",
    "    file.write('socrates_couple_enabled=.false.\\n\\n')\n",
    "\n",
    "    file.write('# Control configuration\\n')\n",
    "    file.write('display_synopsis_frequency=' + str(display_synopsis_frequency) + '\\n')\n",
    "    file.write('termination_time=' + str(termination_time) + '\\n')\n",
    "    file.write('dtm=' + str(dtm) + '\\n\\n')\n",
    "\n",
    "    file.write('# IO server configuration\\n')\n",
    "    file.write('ioserver_configuration_file=\"' + xmlPath + '\"\\n')\n",
    "    file.write('sname=\"' + modelSname + '\"\\n\"')\n",
    "    file.write('moncs_per_io_server=' + str(monsPerIO) + '\\n')\n",
    "    file.write('sampling_frequency=' + str(sampling_frequency) + '\\n')\n",
    "    file.write('3d_sampling_frequency=' + str(sampling_frequency_3d) + '\\n')\n",
    "    file.write('mm=' + str(mm) + '\\n')\n",
    "    file.write('mm1=' + str(mm1) + '\\n')\n",
    "    file.write('diag_write_freq=' + str(diag_write_freq) + '\\n\\n')\n",
    "\n",
    "    file.write('# Checkpoint configuration\\n')\n",
    "    file.write('checkpoint_frequency=0\\n')\n",
    "    file.write('checkpoint_file=\"moncCheckpoint.nc\"\\n')\n",
    "    file.write('checkpoint_walltime_frequency=10\\n')\n",
    "    file.write('walltime_limit=' + walltime_limit + '\\n\\n')\n",
    "\n",
    "    file.write('# Advection choices\\n')\n",
    "    file.write('advection_flow_fields=pw\\n')\n",
    "    file.write('advection_theta_field=tvd\\n')\n",
    "    file.write('advection_q_fields=tvd\\n\\n')\n",
    "\n",
    "    file.write('# CFL configuration\\n')\n",
    "    file.write('cfl_cvismax=0.2\\n')\n",
    "    file.write('cfl_cvelmax=0.2\\n')\n",
    "    file.write('cfl_dtmmax=2.0\\n')\n",
    "    file.write('cfl_dtmmin=0.001\\n\\n')\n",
    "\n",
    "    file.write('# Simple setup configuration\\n')\n",
    "    file.write('thref0=' + str(thref) + '\\n')\n",
    "    file.write('surface_pressure=' + str(surface_pressure) + '\\n')\n",
    "    file.write('x_size=' + str(x_size) + '\\n')\n",
    "    file.write('y_size=' + str(y_size) + '\\n')\n",
    "    file.write('z_size=' + str(z_size) + '\\n')\n",
    "    file.write('dxx=' + str(dxx) + '\\n')\n",
    "    file.write('dyy=' + str(dyy) + '\\n')\n",
    "    file.write('zztop=' + str(zztop) + '\\n')\n",
    "    file.write('kgd=' + str(kgd) + '\\n')\n",
    "    file.write('hgd=' + str(hgd) + '\\n')\n",
    "    file.write('rmlmax=' + str(rmlmax) + '\\n')\n",
    "    file.write('enable_theta=.true.\\n')\n",
    "    file.write('use_anelastic_equations=.false.\\n')\n",
    "    file.write('passive_th=.false.\\n')\n",
    "    file.write('passive_q=.false.\\n\\n')\n",
    "\n",
    "    file.write('\\n')\n",
    "\n",
    "    file.write('# Initialization of fields\\n')\n",
    "    file.write('l_init_pl_theta=.true.\\n\\n')\n",
    "    file.write('z_init_pl_theta=' + str(z) + '\\n')\n",
    "    file.write('f_init_pl_theta=' + str(th) + '\\n')\n",
    "    file.write('l_init_pl_u=.true.\\n')\n",
    "    file.write('z_init_pl_u=' + str(z) + '\\n')\n",
    "    file.write('f_init_pl_u=' + str(u) + '\\n')\n",
    "    file.write('l_init_pl_v=.true.\\n')\n",
    "    file.write('z_init_pl_v=' + str(z) + '\\n')\n",
    "    file.write('f_init_pl_v=' + str(v) + '\\n')\n",
    "    file.write('l_init_pl_q=.true.\\n')\n",
    "    file.write('names_init_pl_q=' + str(names) + '\\n')\n",
    "    file.write('z_init_pl_q=' + str(z) + '\\n')\n",
    "    #file.write('f_init_pl_q=' + str(q) + ', ' + str(mass) + ', ' + str(number) + '\\n\\n\\n')\n",
    "    file.write('f_init_pl_q=' + str(q) + ', ' + str(mass_Accu) + ', ' + str(num_Accu) + str(mass_Aitk) + str(num_Aitk) + '\\n\\n\\n')\n",
    "    \n",
    "    file.write('# Random noise\\n')\n",
    "    file.write('l_rand_pl_theta=.true.\\n')\n",
    "    file.write('z_rand_pl_theta=' + str(z) + '\\n')\n",
    "    file.write('f_rand_pl_theta=' + str(rand) + '\\n\\n')\n",
    "\n",
    "    file.write('# Simple cloud\\n')\n",
    "    file.write('max_height_cloud=' + str(maxCloudHeight) + '\\n\\n')\n",
    "\n",
    "    file.write('# Roughness lengths\\n')\n",
    "    file.write('z0=' + str(z0) + '\\n')\n",
    "    file.write('z0th=' + str(z0th) + '\\n\\n')\n",
    "\n",
    "    file.write('# Coriolis\\n')\n",
    "    file.write('fcoriol=' + str(fcoriol) + '\\n')\n",
    "    file.write('surface_geostrophic_wind_x=5.0\\n\\n')\n",
    "\n",
    "    file.write('# Damping configuration\\n')\n",
    "    file.write('dmptim=' + str(dmptim) + '\\n')\n",
    "    file.write('zdmp=' + str(zdmp) + '\\n')\n",
    "    file.write('hdmp=' + str(hdmp) + '\\n\\n')\n",
    "\n",
    "    file.write('# Subsidence profile\\n')\n",
    "    file.write('l_subs_pl_theta=.true.\\n')\n",
    "    file.write('z_subs_pl=' + str(zSubs) + '\\n')\n",
    "    file.write('f_subs_pl=' + str(fSubs) + '\\n')\n",
    "    file.write('l_subs_pl_q=.true.\\n\\n')\n",
    "\n",
    "    file.write('#SUBSIDENCE=1, DIVERGENCE=0\\n')\n",
    "    file.write('subsidence_input_type=0\\n\\n')\n",
    "\n",
    "    file.write('# Socrates\\n')\n",
    "    file.write('i_cloud_representation = 1\\n')\n",
    "    file.write('latitude = ' + str(lat) + '\\n')\n",
    "    file.write('longitude = ' + str(lon) + '\\n')\n",
    "    file.write('rad_start_year = ' + str(rad_start_year) + '\\n')\n",
    "    file.write('rad_start_day = ' + str(rad_start_day) + '\\n')\n",
    "    file.write('rad_start_time = ' + str(rad_start_time) + '\\n')\n",
    "    file.write('rad_int_time = 0\\n')\n",
    "    file.write('surface_albedo = ' + str(surface_albedo) + '\\n\\n')\n",
    "\n",
    "    file.write('mphys_nq_l=1\\n')\n",
    "    file.write('mphys_nd_l=1\\n')\n",
    "    file.write('mphys_nq_r=1\\n')\n",
    "    file.write('mphys_nq_i=1\\n')\n",
    "    file.write('mphys_nq_s=1\\n')\n",
    "    file.write('mphys_nq_g=1\\n\\n')\n",
    "\n",
    "    file.write('# Casim options\\n')\n",
    "    file.write('option=22222\\n')\n",
    "    file.write('l_warm=.false.\\n\\n')\n",
    "\n",
    "    file.write('iopt_act=' + str(act) + '\\n')\n",
    "    file.write('iopt_inuc=' + str(inuc) + '\\n')\n",
    "    file.write('process_level=' + str(process_level) + '\\n')\n",
    "    file.write('aerosol_option=' + str(aeroOption) + '\\n')\n",
    "    file.write('l_override_checks=.true.\\n\\n')\n",
    "\n",
    "    file.write('number_q_fields=' + str(q_fields) + '\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}